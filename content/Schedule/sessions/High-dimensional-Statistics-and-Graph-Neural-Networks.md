---
title: "High-dimensional Statistics and Graph Neural Networks"
summary: "1:30 p.m. — 3:00 p.m., Friday, Aug. 25, 2023"
tags: "s1-4"
weight: 6
---

Friday, Aug. 25, 2023
------


<hr style="border: 0; border-top: 5px solid;">

<div class="tip">
    <img class="icon" src="/icon/yanjiang.png" />
    Session: <span class="font-bold" style="font-size:120%">High-dimensional Statistics and Graph Neural Networks</span>
</div>

<div class="tip">
    <img class="icon" src="/icon/shizhong.png" />
    Time: 1:30 p.m. — 3:00 p.m.
</div>
<div class="tip">
    <img class="icon" src="/icon/didian.png" />
    location: 华东师范大学中北校区 文史楼215
</div>


<div class="tip">
    <img class="icon" src="/icon/lingdao.png" />
    Session Chair: Jianxin Yin, Renmin University of China
</div>


________________________________________

<div class="row">
    <div class="left">
        <img src="/images/weidong.png" class="avatar" />
        <div class="font-small font-bold">
            <a>
                Weidong Liu
            </a>
        </div>
    </div>
    <div class="right">
        <div class="font-small">
            <u>Title:</u> &nbsp;
            TBA
        </div>
        <div class="content font-small">
            <u>Abstract:</u> &nbsp;
            TBA
        </div>
    </div>
</div>

<div class="row">
    <div class="left">
        <img src="/images/linqian.png" class="avatar" />
        <div class="font-small font-bold">
            <a>
                Qian Lin
            </a>
        </div>
    </div>
    <div class="right">
        <div class="font-small">
            <u>Title:</u> &nbsp;
            Recent Advances in Kernel Regression and Its Application in Deep Neural Networks
        </div>
        <div class="content font-small">
            <u>Abstract:</u> &nbsp;
            We will provide a brief summary of some results appeared in kernel regression/deep neural network and propose some potential directions.
        </div>
    </div>
</div>

<div class="row">
    <div class="left">
        <img src="/images/zhewei.png" class="avatar" />
        <div class="font-small font-bold">
            <a>
                Zhewei Wei
            </a>
        </div>
    </div>
    <div class="right">
        <div class="font-small">
            <u>Title:</u> &nbsp;
            谱域图神经网络理论基础
        </div>
        <div class="content font-small">
            <u>Abstract:</u> &nbsp;
            近年来，由于图结构数据的强大表达能力，用机器学习方法分析和挖掘图数据的研究越来越受到重视。图神经网络（Graph Neural Networks）是一类基于深度学习的处理图数据的方法，在众多领域展现出了卓越的性能，其已经成为一种广泛应用的图分析方法。谱域图神经网络是图神经网络研究中一类重要的方法，它们在拉普拉斯谱域中设计和学习不同的图卷积，具有良好的理论保证和可解释性。本报告拟先介绍图神经网络的任务和一些前沿应用，然后从图傅里叶变换、图卷积的设计和图谱滤波器的多项式近似等方面探讨谱域图神经网络的理论基础，最后将讨论我们在谱域图神经网络所做的一些工作和对未来工作的展望。
        </div>
    </div>
</div>

<div class="row">
    <div class="left">
        <img src="/images/weichi.png" class="avatar" />
        <div class="font-small font-bold">
            <a>
                Weichi Wu
            </a>
        </div>
    </div>
    <div class="right">
        <div class="font-small">
            <u>Title:</u> &nbsp;
            Time-Varying Correlation Network Analysis of Non-Stationary Multivariate Time Series With Complex Trends
        </div>
        <div class="content font-small">
            <u>Abstract:</u> &nbsp;
            This paper proposes a flexible framework for inferring large-scale time-varying and time-lagged correlation networks from multivariate or high-dimensional non-stationary time series with piecewise smooth trends. Built on a novel and unified multiple-testing procedure of time-lagged cross-correlation functions with a fixed or diverging number of lags, our method can accurately disclose flexible time-varying network structures associated with complex functional structures at all time points. We broaden the applicability of our method to the structure breaks by developing difference-based nonparametric estimators of cross-correlations, achieve accurate family-wise error control via a bootstrap-assisted procedure adaptive to the complex temporal dynamics, and enhance the probability of recovering the time-varying network structures using a new uniform variance reduction technique. We prove the asymptotic validity of the proposed method and demonstrate its effectiveness in finite samples through simulation studies and empirical applications.
        </div>
    </div>
</div>

<style>

.tip {
    height: 30px;
    line-height: 30px;
}

.icon {
    width: 15px;
}

.row {
    padding: 10px; 
    height: auto; 
    border-bottom-width: 2px; 
    border-style: solid; 
    border-color: #E4E7ED; 
    padding-bottom: 20px; 
    padding-top: 20px;
    display: flex; 
    text-align: justify;
}

.left {
    min-width: 150px !important;
    text-align: center;
}

.avatar {
    width: 120px;
    height: 160px;
    max-width: 100%;
    border-radius: 10px;
}

.right {
    margin-left: 10px; 
    max-width: 80%;
}


.font-small {
    /* font-size: 16px; */
}

.font-bold {
    font-weight: bold;
}
</style>